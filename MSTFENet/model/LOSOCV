import datetime
from scipy.signal import butter, filtfilt
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts
def bandpass_filter(data, low=8, high=30, fs=250, order=5):
    nyq = 0.5 * fs
    b, a = butter(order, [low/nyq, high/nyq], btype='band')
    return filtfilt(b, a, data)
from sklearn.metrics import cohen_kappa_score, f1_score, accuracy_score
from data.data_util import *
from utils import *
torch.set_num_threads(10)
# 设备配置
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")
import numpy as np
from torch.utils.data import Dataset, DataLoader
import os
import time
from tqdm import tqdm
import pandas as pd

# ===== SubjectDataset =====
class SubjectDataset(Dataset):
    def __init__(self, subject_ids, base_path):
        """
        Args:
            subject_ids (list): ['A01','A02',...]
            base_path (str): your data path
        """
        self.data = []
        self.labels = []

        # Load data for all specified subjects.
        for sid in subject_ids:
            train_datafile =   str(sid) + 'T'
            test_datafile =  str(sid) + 'E'
            # 加载E条件数据
            train_data, train_labels = load_data(base_path, train_datafile)
            test_data, test_labels = load_data(base_path, test_datafile)



            # Combined train data and test data
            combined_data = np.concatenate([train_data, test_data], axis=0)
            combined_labels = np.concatenate([train_labels, test_labels], axis=0)
            # combined_data = bandpass_filter(combined_data)
            self.data.append(combined_data)
            self.labels.append(combined_labels)

        # Convert to a single array.
        self.data = np.concatenate(self.data)
        self.labels = np.concatenate(self.labels)


    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        # to tensor
        sample = torch.tensor(self.data[idx], dtype=torch.float32).unsqueeze(0)  # (C, ...)
        label = torch.tensor(self.labels[idx], dtype=torch.long)
        return sample, label


# ===== MSTFENet =====
from braindecode.models.eegnet import Conv2dWithConstraint
from einops import rearrange

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.nn import init


class ECAAttention(nn.Module):

    def __init__(self, kernel_size=3):
        super().__init__()
        self.gap = nn.AdaptiveAvgPool2d(1)
        self.conv = nn.Conv1d(1, 1, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)
        self.sigmoid = nn.Sigmoid()

    def init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                init.kaiming_normal_(m.weight, mode='fan_out')
                if m.bias is not None:
                    init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                init.constant_(m.weight, 1)
                init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                init.normal_(m.weight, std=0.001)
                if m.bias is not None:
                    init.constant_(m.bias, 0)

    def forward(self, x):
        y = self.gap(x)
        y = y.squeeze(-1).permute(0, 2, 1)
        y = self.conv(y)
        y = self.sigmoid(y)
        y = y.permute(0, 2, 1).unsqueeze(-1)
        return x * y.expand_as(x)


class ChannelFusion(nn.Module):
    def __init__(self, in_channels):
        super(ChannelFusion, self).__init__()
        self.avgPool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        self.conv = nn.Conv2d(in_channels//2, in_channels//2, 1, bias=False)
        self.sigmoid = nn.Sigmoid()
        self.elu = nn.ELU()

    def forward(self, x):
        avg_out = self.avgPool(x)
        max_out = self.max_pool(x)
        out = avg_out + max_out
        out = self.elu(out)
        out = self.conv(out)
        return self.sigmoid(out)


class LocalTemporalFusion(nn.Module):
    def __init__(self, kernel_size=7):
        super(LocalTemporalFusion, self).__init__()
        self.conv1 = nn.Conv2d(2, 1, 7, padding=kernel_size // 2, bias=False)
        self.conv2 = nn.Conv2d(2, 1, 9, padding=4, bias=False)
        self.conv3 = nn.Conv2d(2, 1, 3, padding=1, bias=False)
        self.conv4 = nn.Conv2d(2, 1, 5, padding=2, bias=False)
        self.conv = nn.Conv2d(1, 1, 1, bias=False)
        self.sigmoid = nn.Sigmoid()
        # self.bn = nn.BatchNorm2d(1)

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x = torch.cat([avg_out, max_out], dim=1)
        split_tensors = []
        for i in range(4):
            start_idx = i * x.size(3) // 4
            end_idx = start_idx + x.size(3) // 4
            split_tensors.append(x[:, :, :, start_idx:end_idx])

        outputs = []
        for i, split_tensor in enumerate(split_tensors):
            if i == 0:
                output = self.conv1(split_tensor)
            elif i == 1:
                output = self.conv2(split_tensor)
            elif i == 2:
                output = self.conv3(split_tensor)
            elif i == 3:
                output = self.conv4(split_tensor)
            outputs.append(output)
        x = torch.cat(outputs, dim=3)
        x = self.conv(x)
        return self.sigmoid(x)


class FusionConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(FusionConv, self).__init__()
        self.down =  nn.Conv2d(in_channels, in_channels//2, kernel_size=1)
        self.conv_3x3 = nn.Conv2d(in_channels//2, in_channels//2, kernel_size=3, stride=1, padding=1)
        self.conv_5x5 = nn.Conv2d(in_channels//2, in_channels//2, kernel_size=5, stride=1, padding=2)
        self.conv_7x7 = nn.Conv2d(in_channels//2, in_channels//2, kernel_size=7, stride=1, padding=3)
        self.local_fusion = LocalTemporalFusion()
        self.channel_fusion = ChannelFusion(in_channels)
        self.conv = nn.Conv2d(in_channels//2, out_channels, kernel_size=1)

    def forward(self, x1, x2):
        x_fused = torch.cat([x1, x2], dim=1)
        x_fused = self.down(x_fused)

        x_fused_c = x_fused * self.channel_fusion(x_fused)
        x_3x3 = self.conv_3x3(x_fused)
        x_5x5 = self.conv_5x5(x_fused)
        x_7x7 = self.conv_7x7(x_fused)
        x_fused_s = x_3x3 + x_5x5 + x_7x7
        x_fused_s = x_fused_s * self.local_fusion(x_fused_s)
        x_out = self.conv(x_fused_s + x_fused_c)
        return x_out


class MSFF(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(MSFF, self).__init__()
        self.fusion_conv = FusionConv(in_channels, out_channels)
        self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)

    def forward(self, x1, x2):
        x_fused = self.fusion_conv(x1, x2)
        x3 = torch.cat([x1, x2], dim=1)
        cut = self.shortcut(x3)
        return x_fused + cut


class Branch_Right(nn.Module):
    def __init__(self, in_channels):
        super(Branch_Right, self).__init__()
        out_channels = in_channels

        self.project1 = nn.Sequential(
            nn.Conv2d(out_channels, out_channels, 1, bias=False),
            nn.BatchNorm2d(out_channels), )

        self.project2 = nn.Sequential(
            nn.Conv2d(out_channels, 2 * out_channels, 1, bias=False),
            nn.BatchNorm2d(2 * out_channels), )

    def forward(self, x0, x1, x2, x3):
        B, T, N, C = x0.shape
        x_ = torch.cat([x0, x1, x2, x3], 0)
        x__ = x_.reshape(-1, T, N * B, C)
        x__ = self.project1(x__.permute(0, 3, 2, 1)).permute(0, 3, 2, 1)
        weight = F.softmax(x__, dim=0)
        x_ = x_.reshape(-1, T, N * B, C)
        out = (weight * x_).sum(0)
        out = out.reshape(B, T, N, C)
        return self.project2(out.permute(0, 3, 2, 1)).permute(0, 3, 2, 1)


class gatedFusion(nn.Module):

    def __init__(self, dim):
        super(gatedFusion, self).__init__()
        self.fc1 = nn.Linear(dim, dim, bias=True)
        self.fc2 = nn.Linear(dim, dim, bias=True)

    def forward(self, x1, x2):
        x11 = self.fc1(x1)
        x22 = self.fc2(x2)

        z = torch.sigmoid(x11 + x22)

        out = z * x1 + (1 - z) * x2
        return out


class VarPoold(nn.Module):
    def __init__(self, kernel_size, stride):
        super().__init__()
        self.kernel_size = kernel_size
        self.stride = stride

    def forward(self, x):
        t = x.shape[2]
        out_shape = (t - self.kernel_size) // self.stride + 1
        out = []

        for i in range(out_shape):
            index = i * self.stride
            input = x[:, :, index:index + self.kernel_size]
            output = torch.log(torch.clamp(input.var(dim=-1, keepdim=True), 1e-6, 1e6))
            out.append(output)

        out = torch.cat(out, dim=-1)

        return out


def attention(query, key, value):
    dim = query.size(-1)
    scores = torch.einsum('bhqd,bhkd->bhqk', query, key) / dim ** .5
    attn = F.softmax(scores, dim=-1)
    out = torch.einsum('bhqk,bhkd->bhqd', attn, value)
    return out, attn


class MultiHeadedAttention(nn.Module):
    def __init__(self, d_model, n_head, dropout):
        super().__init__()
        self.d_k = d_model // n_head
        self.d_v = d_model // n_head
        self.n_head = n_head

        self.w_q = nn.Linear(d_model, n_head * self.d_k)
        self.w_k = nn.Linear(d_model, n_head * self.d_k)
        self.w_v = nn.Linear(d_model, n_head * self.d_v)
        self.w_o = nn.Linear(n_head * self.d_v, d_model)

        self.dropout = nn.Dropout(dropout)

    # [batch_size, n_channel, d_model]
    def forward(self, query, key, value):
        q = rearrange(self.w_q(query), "b n (h d) -> b h n d", h=self.n_head)
        k = rearrange(self.w_k(key), "b n (h d) -> b h n d", h=self.n_head)
        v = rearrange(self.w_v(value), "b n (h d) -> b h n d", h=self.n_head)

        out, _ = attention(q, k, v)

        out = rearrange(out, 'b h q d -> b q (h d)')
        out = self.dropout(self.w_o(out))

        return out


class FeedForward(nn.Module):
    def __init__(self, d_model, d_hidden, dropout):
        super().__init__()
        self.w_1 = nn.Linear(d_model, d_hidden)
        self.act = nn.ReLU()
        self.w_2 = nn.Linear(d_hidden, d_model)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        x = self.w_1(x)
        x = self.act(x)
        x = self.dropout(x)
        x = self.w_2(x)
        x = self.dropout(x)

        return x


class TransformerEncoder(nn.Module):
    def __init__(self, dim, heads, fc_ratio, attn_dropout=0.5, fc_dropout=0.5):
        super().__init__()
        self.multihead_attention = MultiHeadedAttention(dim, heads, attn_dropout)
        self.feed_forward = FeedForward(dim, dim * fc_ratio, fc_dropout)
        self.layernorm1 = nn.LayerNorm(dim)
        self.layernorm2 = nn.LayerNorm(dim)

    def forward(self, data):
        out = data + self.multihead_attention(data, data, data)
        res = self.layernorm1(out)
        res = out + self.feed_forward(res)
        output = self.layernorm2(res)
        return output


class MyModel1(nn.Module):
    def __init__(self, num_classes=4, num_samples=1000, num_channels=22, embed_dim=32, pool_size=50,
    pool_stride=15, num_heads=8, fc_ratio=4, depth=4, attn_drop=0.5, fc_drop=0.5):
        super().__init__()

        self.temp_Conv1 = nn.Sequential(
            Conv2dWithConstraint(1,32 // 4, kernel_size=[1, 51], padding=(0, 25),groups=1),
            nn.BatchNorm2d(32 // 4),
        )
        self.temp_Conv2 = nn.Sequential(
            Conv2dWithConstraint(1, 32 // 4, kernel_size=[1, 25], padding=(0, 12),groups=1),
            nn.BatchNorm2d(32 // 4),
        )
        self.temp_Conv3 = nn.Sequential(
            Conv2dWithConstraint(1, 32 // 4, kernel_size=[1, 15], padding=(0, 7),groups=1),
            nn.BatchNorm2d(32 // 4),
        )
        self.spatial_1 = nn.Sequential(
            Conv2dWithConstraint(8, 8, (22, 1), padding=0,  bias=False),
            nn.BatchNorm2d(8),
            nn.Dropout(0.25),
            Conv2dWithConstraint(8, 8, kernel_size=[1, 1], padding='valid',
                                ),
            nn.BatchNorm2d(8),
        )
        self.spatial_2 = nn.Sequential(
            Conv2dWithConstraint(8, 8, kernel_size=[22, 1], padding='valid',
                                 ),
            nn.BatchNorm2d(8),
            nn.Dropout(0.25),
            Conv2dWithConstraint(8, 8, kernel_size=[1, 1], padding='valid',
                                 ),
            nn.BatchNorm2d(8),
        )
        self.spatial_3 = nn.Sequential(
            Conv2dWithConstraint(8, 8, kernel_size=[22, 1], padding='valid',
                                 max_norm=2.),
            nn.BatchNorm2d(8),
            nn.Dropout(0.25),
            Conv2dWithConstraint(8, 8, kernel_size=[1, 1], padding='valid',
                                 max_norm=2.),
            nn.BatchNorm2d(8),
        )
        self.elu = nn.ELU()
        self.varPool = VarPoold(pool_size, pool_stride)
        self.avgPool = nn.AvgPool1d(pool_size, pool_stride)
        self.dropout = nn.Dropout()
        self.transformer_encoders = nn.ModuleList(
            [TransformerEncoder(24, 8,4, 0.5, 0.5) for _ in range(depth)]
        )
        self.msff = MSFF(in_channels=2 * 32, out_channels=32)
        self.branch_left = nn.Sequential(
            nn.Conv2d(32, 32, (2, 1)),
            nn.BatchNorm2d(32),
            nn.ELU()
        )
        self.branch_right = Branch_Right(in_channels=6)
        self.eca = ECAAttention(kernel_size=3)
        self.gt = gatedFusion(dim=1)
        self.classify = nn.Linear(24 * 32, 4)

    def forward(self, x):
        x = x.unsqueeze(dim=1)
        x1 = self.temp_Conv1(x)
        x1 = self.spatial_1(x1)
        x2 = self.temp_Conv2(x)
        x2 = self.spatial_2(x2)
        x3 = self.temp_Conv3(x)
        x3 = self.spatial_3(x3)
        x = torch.cat((x1, x2, x3), dim=1)
        x = self.elu(x)
        x = x.squeeze(dim=2)
        x1 = self.avgPool(x)
        x2 = self.varPool(x)
        x1 = self.dropout(x1)
        x2 = self.dropout(x2)
        x1 = rearrange(x1, 'b d n -> b n d')
        x2 = rearrange(x2, 'b d n -> b n d')
        for encoder in self.transformer_encoders:
            x1 = encoder(x1)
            x2 = encoder(x2)
        x1 = x1.unsqueeze(dim=2)
        x1 = x1.reshape(x1.size(0), -1, 2, x1.size(3))
        x2 = x2.unsqueeze(dim=2)
        x2 = x2.reshape(x1.size(0), -1, 2, x1.size(3))
        x = self.msff(x1, x2)
        chunks = torch.chunk(x, 4, dim=3)
        x = self.branch_left(x)
        k = self.branch_right(chunks[0], chunks[1], chunks[2], chunks[3])
        k = k.reshape(k.size(0), k.size(1), 1, -1).permute(0, 1, 3, 2)
        x = x.permute(0, 1, 3, 2)
        z = self.gt(x, k)
        z = self.eca(z)
        z = z.reshape(x.size(0), -1)
        out = self.classify(z)

        return out

# ===== Train model =====
def train_model(model, train_loader, test_loader, criterion, optimizer,scheduler,
                num_epochs=50, test_every=1, subject_id=""):


    # creat log
    global test_kappa, test_f_score
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

    log_dir = f"logs/subject_{subject_id}"
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, f"training_log_{timestamp}.csv")

    # 初始化日志
    logs = []
    best_test_acc = 0.0
    best_kappa = 0.0
    best_f_score = 0.0
    best_epoch = 0


    for epoch in range(num_epochs):
        print(f'\nEpoch {epoch + 1}/{num_epochs}')
        start_time = time.time()


        model.train()


        # use tqdm

        train_iter = tqdm(train_loader, desc=f'Train Epoch {epoch + 1}')

        running_loss = 0.0
        running_corrects = 0
        total_samples = 0
        # train
        model.train()
        for inputs, labels in train_iter:

            inputs = inputs.squeeze(dim=1)
            aug_data, aug_label = data_augmentation(inputs, labels,batch_size=64)
            inputs = torch.cat((inputs, aug_data), dim=0)
            labels = torch.cat((labels, aug_label), dim=0)


            inputs = inputs.float().to(device)
            labels = labels.long().to(device)


            actual_batch_size = inputs.size(0)
            total_samples += actual_batch_size


            optimizer.zero_grad()
            outputs = model(inputs)

            loss = criterion(outputs, labels)

            loss.backward()

            optimizer.step()
            scheduler.step()

            _, preds = torch.max(outputs, 1)
            running_loss += loss.item() * actual_batch_size
            running_corrects += torch.sum(preds == labels.data).item()


        epoch_loss = running_loss / total_samples
        epoch_acc = running_corrects / total_samples
        train_time = time.time() - start_time

        # test
        if (epoch + 1) % test_every == 0:
            test_acc, test_loss,test_kappa,test_f_score = evaluate_model(model, test_loader, criterion)
            print(f'Test Acc: {test_acc:.4f}, Test Loss: {test_loss:.4f}')
        else:
            test_acc, test_loss = -1, -1


        if test_acc > best_test_acc:
            best_test_acc = test_acc
            best_epoch = epoch + 1
            best_kappa = test_kappa
            best_f_score = test_f_score

            torch.save(model.state_dict(), os.path.join(log_dir, f'best_model.pth'))

        # save log
        log_entry = {
            'epoch': epoch + 1,
            'train_loss': epoch_loss,
            'train_acc': float(epoch_acc),
            'test_loss': test_loss,
            'test_acc': float(test_acc) if test_acc != -1 else None,
            'time': train_time,
            'best_test_acc': best_test_acc,
            'best_epoch': best_epoch,
            'best_kappa': best_kappa,
            'best_f_score': best_f_score
        }
        logs.append(log_entry)

        # print information
        print(f"Time: {train_time:.2f}s, Train Loss: {epoch_loss:.4f}, Train Acc: {float(epoch_acc):.4f}, Best Acc: {float(best_test_acc):.4f}")


        if (epoch + 1) % 5 == 0 or epoch == num_epochs - 1:
            save_logs(logs, log_file)

    # save best log
    save_logs(logs, log_file)
    print(f'Subject {subject_id} complete! Best Test Acc: {best_test_acc:.4f} at epoch {best_epoch}')

    return best_test_acc, logs


def evaluate_model(model, test_loader, criterion):

    model.eval()
    running_loss = 0.0
    running_corrects = 0
    test_predicted = []
    test_actual = []
    total_samples = 0
    with torch.no_grad():
        test_iter = tqdm(test_loader, desc='Testing')
        for inputs, labels in test_iter:
            inputs = inputs.to(device)
            labels = labels.to(device)
            inputs = inputs.squeeze(dim= 1)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            _, preds = torch.max(outputs, 1)
            batch_size = inputs.size(0)
            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)
            test_predicted.extend(torch.max(outputs, 1)[1].cpu().tolist())
            test_actual.extend(labels.cpu().tolist())
            total_samples += batch_size  # 累计样本数

            # 更新进度条
            test_iter.set_postfix({
                'Loss': running_loss /  total_samples ,
                'Acc': float(running_corrects) /  total_samples
            })

    test_loss = running_loss / len(test_loader.dataset)

    test_acc = accuracy_score(test_actual, test_predicted)

    test_kappa = cohen_kappa_score(test_actual, test_predicted)
    test_f_score = f1_score(test_actual, test_predicted, average='weighted')
    return float(test_acc), test_loss,test_kappa,test_f_score


def save_logs(logs, filepath):
    # save log as csv
    df = pd.DataFrame(logs)
    df.to_csv(filepath, index=False)


# ===== LOSOCV method =====
def loso_cross_validation(base_path, all_subjects, num_epochs=100, test_every=1):

    results = {}
    all_logs = {}

    # Iterate through each subject as the test set.
    for i, test_subject in enumerate(all_subjects):

        print(f"\n{'=' * 50}")
        print(f"Subject {i + 1}/{len(all_subjects)}: Test subject {test_subject}")
        print(f"{'=' * 50}")

        # Divide the subjects.
        train_subjects = [s for s in all_subjects if s != test_subject]

        # load dataset
        start_time = time.time()
        print("Loading datasets...")
        train_dataset = SubjectDataset(train_subjects, base_path)
        test_dataset = SubjectDataset([test_subject], base_path)
        print(f"Loaded {len(train_dataset)} training samples, {len(test_dataset)} test samples")

        # dataloader
        batch_size = 64
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
        load_time = time.time() - start_time
        print(f"Data loaded in {load_time:.2f} seconds")

        # check the input shape
        sample, label = next(iter(train_loader))
        input_shape = sample.shape[1:]  # (C, H, W)
        num_classes = len(torch.unique(label))
        print(f"Input shape: {input_shape}, Num classes: {num_classes}")

        # init
        model = MyModel1(num_classes=num_classes).to(device)

        # Loss and optimizer
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(model.parameters(),
                             lr=0.001,
                             weight_decay=0.001)
        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=30, T_mult=1, eta_min=0.0002)

        # train
        start_train = time.time()
        test_acc, logs = train_model(
            model, train_loader, test_loader, criterion, optimizer,scheduler,
            num_epochs=num_epochs,
            test_every=test_every,
            subject_id=test_subject
        )
        train_time = time.time() - start_train
        print(f"Training complete for {test_subject} in {train_time:.2f} seconds")

        # log
        results[test_subject] = test_acc
        all_logs[test_subject] = logs

        # Clear memory.
        del model, train_dataset, test_dataset, train_loader, test_loader
        torch.cuda.empty_cache()

    # final
    print("\n\nFinal LOSO Results:")
    for subj, acc in results.items():
        print(f"Subject {subj}: {acc:.4f}")

    avg_acc = sum(results.values()) / len(results)
    print(f"\nAverage Accuracy: {avg_acc:.4f}")

    # save final result
    summary = pd.DataFrame.from_dict(results, orient='index', columns=['Accuracy'])
    summary.loc['Average'] = avg_acc
    summary.to_csv('logs/loso_results_summary.csv')

    return results, all_logs

def data_augmentation( data, label,batch_size):
        aug_data = []
        aug_label = []

        N, C, T = data.shape
        seg_size = T // 8
        aug_data_size = batch_size // 4

        for cls in range(4):
            cls_idx = np.where(label == cls)
            cls_data = data[cls_idx]
            data_size = cls_data.shape[0]
            if data_size == 0 or data_size == 1:
                continue
            temp_aug_data = np.zeros((aug_data_size, C, T))
            for i in range(aug_data_size):
                rand_idx = np.random.randint(0, data_size, 8)
                for j in range(8):
                    temp_aug_data[i, :, j * seg_size:(j + 1) * seg_size] = cls_data[rand_idx[j], :,
                                                                           j * seg_size:(j + 1) * seg_size]
            aug_data.append(temp_aug_data)
            aug_label.extend([cls] * aug_data_size)

        aug_data = np.concatenate(aug_data, axis=0)
        aug_label = np.array(aug_label)

        aug_shuffle = np.random.permutation(len(aug_data))
        aug_data = aug_data[aug_shuffle, :, :]
        aug_label = aug_label[aug_shuffle]

        aug_data = torch.from_numpy(aug_data)
        aug_label = torch.from_numpy(aug_label)

        return aug_data, aug_label
# ===== main =====
if __name__ == "__main__":
    #
    DATA_PATH = r"you data path"
    ALL_SUBJECTS = [f"A0{i}" for i in range(1, 10)]


    torch.manual_seed(0)
    np.random.seed(0)


    results, all_logs = loso_cross_validation(
        DATA_PATH,
        ALL_SUBJECTS,
        num_epochs=300,
        test_every=1
    )

